# Stoked CLI Environment Variables

#
# LLM CONFIGURATION
#

# LLM Mode: OLLAMA or OPENAI (default: OLLAMA)
LLM_MODE=OLLAMA

# OpenAI Configuration (required when LLM_MODE=OPENAI)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o

# Ollama Configuration (required when LLM_MODE=OLLAMA)
OLLAMA_MODEL=llama3.2:latest
OLLAMA_HOST=http://localhost:11434

#
# JSDOCS CONFIGURATION
#

# JSDoc processing mode: DEFAULT or BATCH (default: DEFAULT)
# BATCH mode is only available with OpenAI
JSDOCS_MODE=DEFAULT

# Batch processing configuration (when JSDOCS_MODE=BATCH)
BATCH_POLL_INTERVAL_SEC=5
BATCH_SIZE=10

# JSDoc test mode (for running tests without actually modifying files)
JSDOCS_TEST_MODE=false

#
# GITHUB CONFIGURATION
#

# GitHub personal access token (required for repo operations)
GITHUB_TOKEN=your_github_token_here

#
# WORKSPACE CONFIGURATION
#

# Root directory for repositories (default: ~/.stoked/.repos)
STOKED_WORKSPACE_ROOT=~/.stoked/.repos

#
# LOGGING CONFIGURATION
#

# Log level: debug, info, warn, error (default: info)
STOKED_LOG_LEVEL=info

# Enable detailed timing information (for debugging)
TIMING_DEBUG=false

# JSDoc concurrency level (number of files to process in parallel)
JSDOC_CONCURRENCY=5 